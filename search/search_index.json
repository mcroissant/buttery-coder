{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#intro","title":"Intro","text":"<p>This is a small space where I try to collect some of the content, thoughts and learning I have throughout the years. </p> <p>I hope you'll find insightful content in here and that I will give back a tiny share of the knowledge that has been shared with me...</p>"},{"location":"#main-content","title":"Main content","text":"<p>You'll find two things in here : </p> <ul> <li>blog post which are just a collection of topics of interests throughout the years.</li> <li>courses which are more structured content aimed at sharing on a specific domain</li> </ul>"},{"location":"blog/","title":"Home","text":""},{"location":"blog/2020/07/10/your-code-first-api-needs-validation/","title":"Your code-first API needs validation","text":"<p>When you start a project you might tend to do code first API as this is a well-known territory for most developers, especially with frameworks like Spring Boot which use powerful annotations to generate your API and specifications.</p> <p>In a matter of a few lines, you have a simple CRUD API up and running. But that\u2019s not the end of the story, people need to consume it next. And as they are looking at consuming your API the first thing they will turn to is your documentation, specification, and associated testing UI.</p> <p>You would think that the code-first approach and auto-generation of your OpenAPI specification got you covered. Sadly most of the time your specification will be invalid.</p> <p>The root cause for your invalid specs is usually quite simple, the OpenAPI schema validation was not implemented in the annotation you use in your code. In itself, the invalid schema won\u2019t prevent you from serving and consuming the API but it will prevent you from using the whole set of open source tools that are relying on it like the one in this collection of links: OpenApi Tools</p> <p></p> <p>To cope with the situation I propose to introduce you to a very handy tool called spectral Spectral</p>"},{"location":"blog/2020/07/10/your-code-first-api-needs-validation/#generating-openapi-specs-at-build-time","title":"Generating OpenAPI specs at build time","text":"<p>Before jumping into validation of your API specs the first thing you need to do in code first is to grasp a copy of the spec which is usually only exposed while running your project. To do so I propose for those of you using Java and spring boot a simple build plugin using springdoc Springdoc</p> <pre><code>...\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;VERSION HERE&lt;/version&gt;\n            &lt;configuration&gt;\n                &lt;wait&gt;2000&lt;/wait&gt;\n                &lt;jvmArguments&gt;-Dspring.application.admin.enabled=true&lt;/jvmArguments&gt;\n            &lt;/configuration&gt;\n            &lt;executions&gt;\n                &lt;execution&gt;\n                    &lt;id&gt;pre-integration-test&lt;/id&gt;\n                    &lt;goals&gt;\n                        &lt;goal&gt;start&lt;/goal&gt;\n                    &lt;/goals&gt;\n                &lt;/execution&gt;\n                &lt;execution&gt;\n                    &lt;id&gt;post-integration-test&lt;/id&gt;\n                    &lt;goals&gt;\n                        &lt;goal&gt;stop&lt;/goal&gt;\n                    &lt;/goals&gt;\n                &lt;/execution&gt;\n            &lt;/executions&gt;\n        &lt;/plugin&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.springdoc&lt;/groupId&gt;\n            &lt;artifactId&gt;springdoc-openapi-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;VERSION HERE&lt;/version&gt;\n            &lt;executions&gt;\n                &lt;execution&gt;\n                    &lt;id&gt;integration-test&lt;/id&gt;\n                    &lt;goals&gt;\n                        &lt;goal&gt;generate&lt;/goal&gt;\n                    &lt;/goals&gt;\n                &lt;/execution&gt;\n            &lt;/executions&gt;\n            &lt;configuration&gt;\n                &lt;apiDocsUrl&gt;http://localhost:8080/api-docs&lt;/apiDocsUrl&gt;\n                &lt;outputFileName&gt;openapi.json&lt;/outputFileName&gt;\n                &lt;outputDir&gt;${project.build.directory}&lt;/outputDir&gt;\n                &lt;skip&gt;false&lt;/skip&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n...\n&lt;/build&gt;\n</code></pre>"},{"location":"blog/2020/07/10/your-code-first-api-needs-validation/#ci-validation","title":"CI validation","text":"<p>Once you have managed to generate an OpenApi spec out of your code-first API it is time to validate it using spectral. Spectral contains out-of-the-box an OpenApi schema validator and is able to parse JSON or YAML all the same.</p> <p>Spotlight provides a container image with spectral installed and all required dependency which allows for a very straightforward gitlab-ci definition of the validation step.</p> <pre><code>stages:\n  - validate\n\nvalidate_open-api:\n  stage: validate\n  image:\n    name: stoplight/spectral\n    entrypoint: [\"\"]\n  script:\n    - spectral lint request-apispec.json -f junit -o api-report.xml\n  artifacts:\n    when: always\n    paths:\n      - api-report.xml\n    reports:\n      junit: api-report.xml\n</code></pre> <p>What you want to note here except for the regular calls to spectral lint is the usage of the JUnit format and output to an XML file. The file is later reused as a report so you can visualize the linter output in a nicer way.</p> <p></p>"},{"location":"blog/2020/07/10/your-code-first-api-needs-validation/#creating-a-custom-rule","title":"Creating a custom rule","text":"<p>The power of spectral lies in its rulesets, they provide you with the basic set of rules to be applied to your document. But if you want to go further spectral allows you to extend and even override those rulesets Rulesets</p> <p>To illustrate the kind of extra rules you might want to implement here is a simple rule to check you are only using HTTPS endpoints.</p> <pre><code>extends: spectral:oas\nrules:\n   endpoint-should-be-https:\n    description: Endpoints should be using https\n    given: $.servers[*]\n    severity: error\n    then:\n      field: url\n      function: pattern\n      functionOptions:\n        match: \"^https\"\n</code></pre>"},{"location":"blog/2020/07/10/your-code-first-api-needs-validation/#what-are-the-next-steps","title":"What are the next steps ?","text":"<p>If you want to go further I would suggest some deep dive in the spectral documentation: Spectral Documentation</p> <p>Have a look at this great article from Joyce Lin: Joyce Lin</p> <p>I would check out how you can enable local build OpenAPI specification validation using spectral in your build scripts</p> <p>Then maybe you could reflect on having common API specification rules for your company?</p> <p>What would you do next?</p>"},{"location":"blog/2019/04/09/real-time-opc-ua-tags-monitoring-in-the-cloud-with-aws-iot/","title":"Real-time OPC-UA tags monitoring in the cloud with AWS IoT","text":"<p>Wouldn\u2019t it be nice to see your field data in (near) real-time? To be able to build a powerful dashboard in a matter of minutes to monitor your process, or start digitizing your visual management practices.</p> <p></p> <p>We all have of favorite OPC server depending on the task, but for me it is Kepware. The nice thing about OPC servers is usually that they cover way more communication protocols and allow us to connect to otherwise non-OPC compatible machines.</p> <p>Now with all these collecting capabilities, we need to be able to store, analyze, and display such data. There is of course some powerful tool to do this such as historians like Osi Pi, but what would be nice is if we could set up as scalable solution within minutes with unlimited integration and that\u2019s where cloud solution comes handy.</p> <p>Luckily for us, Kepware got us covered and is already providing an IoT Gateway that will allow us to choose tag which should be forwarded to the cloud.</p> <p></p> <p>It\u2019s one thing to be able to send data to the cloud in near real-time but what\u2019s important is the ability to do stream processing of these data.</p> <p>What is stream processing? Well it\u2019s the inverse of you regular report generation that is running every X hour or overnight, you look through your data as they come over a time period and compute key metrics or detect events based on value changes</p> <p></p> <p>To achieve our dashboarding goal and real-time analytic we will need to set up a set of AWS services like the Kinesis one shown in the illustration. I did a small change to this architecture by using an elastic search service and Kibana for the dashboarding.</p> <p></p> <p>Kinesis Analytics is an important part of this solution as it will allow you to compute KPIs like MTBF or OEE in near real-time easily. You could also decide to detect some events based on the stream of data and alert the right team in time to fix the issue and so start doing predictive maintenance.</p> <p></p> <p>All our analytics will be streamed to an Elasticsearch service from AWS, this may not be the production tool you are looking for if you have a complex application and dashboarding need. But for monitoring data and putting together a powerful dashboard quickly Kibana which is on top of Elasticsearch will do the work.</p> <p>As part of running this architecture, I conducted a small experiment using the simulation mode of Kepware. The resulting visualization looks like this :</p> <p></p> <p>yes, it is not as fancy as what you can find on the Kibana website but it is a simple visualization of your field data in a near real-time way. The setup of the solution takes around one hour with the detailed step and maybe a bit more than two when trying it for the first time.</p> <p>But in a matter of days, you could produce a set of dashboards to actually make your data and process visible from anywhere. No installation needed aside from your OPC server.</p> <p>I hope you enjoyed this introduction to AWS IOT / Stream analysis, I\u2019m working on putting together a how-to series on the topic with a more advanced configuration like event detection and notification. Please ping me if you\u2019re interested.</p>"},{"location":"blog/2020/07/10/bring-your-opc-ua-tags-to-the-cloud-with-aws-iot-and-kepware/","title":"Bring your OPC-UA tags to the cloud with AWS IoT and Kepware","text":"<p>Today I would like to introduce you to a set of nice functionalities of both Kepware and AWS.</p> <p>We all have of favorite OPC server depending on the task, but for me, it is Kepware without a doubt. No, I\u2019m not sponsored, I just love it! The nice thing about OPC servers is usually that they cover way more communication protocols and allow us to connect to otherwise non-OPC compatible machines.</p>"},{"location":"blog/2020/07/10/bring-your-opc-ua-tags-to-the-cloud-with-aws-iot-and-kepware/#connecting-your-on-premises-opc-server-to-the-cloud","title":"Connecting your on-premises OPC server to the cloud","text":"<p>Now with all these collecting capabilities, we need to be able to store, analyze, and display such data. There is of course some powerful tool to do this such as historians like Osi Pi, but what would be nice is if we could set up as a scalable solution within minutes with unlimited integration and that\u2019s where cloud solution comes handy.</p> <p>Luckily for us, Kepware got us covered and is already providing an IoT Gateway that will allow us to choose tag which should be forwarded to the cloud.</p> <p></p> <p>The first step is to download and set up your kepware server, you can download it by requesting it at https://www.kepware.com/en-us/products/kepserverex/ Once installed if you open the Kepware configuration tool you will find existing tags in there like the simulation examples.</p> <p></p> <p>We now have an OPC server set up on our machine we are ready to tackle the cloud part. To win some time and space I\u2019ll consider you already have your AWS account. Go to Services -&gt; AWS IoT Core and click on the get started button, you should then be redirected to this welcome page.</p> <p></p> <p>For the following part of setting up AWS IoT and Kepware certificates for MQTT communication, I point you to this fine how-to: https://steveunofficialguide.wordpress.com/sending-kepware-data-to-aws-iot-hub/</p> <p>If you did everything alright and added some more tags to your IoT Gateway in Kepware like the simulated tags you should be able to do like me and use the Test interface from AWS IoT to look into the MQTT topic and see your tags being updated</p> <p></p> <p>The next task is to set up a Kinesis stream for forwarding the opc tag values to the analytic component of our solution. Go to Services -&gt; Kinesis -&gt; Data Streams -&gt; Create Kinesis stream</p> <p></p> <p>As this is just a demo let\u2019s keep things simple and not talk about shard yet. Now that we have a Kinesis stream we can ask our IoT service to forward everything there.</p> <p>We go back to AWS IoT Service -&gt; Act -&gt; Create a rule. Give you rule a name</p> <p></p> <p>Give your rule a select statement, I kept it very generic because I have only a single opc tag forwarded but you can play around and filter your data before it gets to the analytic side of thing</p> <p></p> <p>Now we will plug this action to our Kinesis stream, click on Add action button and select Kinesis stream, then find back your previously created stream</p> <p></p> <p>You can now complete the IoT rule creation. To see if you\u2019re alright you can go to the Kinesis stream monitoring tab to see incoming messages from your kepware installation</p> <p></p>"},{"location":"blog/2020/07/10/bring-your-opc-ua-tags-to-the-cloud-with-aws-iot-and-kepware/#consuming-the-opc-tags-and-computing-metrics","title":"Consuming the OPC tags and computing metrics","text":"<p>In the last section, we have set up our data flow from opc tags up to a Kinesis data stream. The data is there and is waiting for us to process it.</p> <p></p> <p>We will now process our opc tags and create some metrics over them, to later on, display those. To do so we will be using AWS Kinesis analytics. It lets you process your data streams using a SQL query like language with additional capabilities like the time windows that we will use.</p> <p>But let\u2019s first create our Kinesis analytics application.</p> <p>Go to AWS -&gt; Services -&gt; Kinesis -&gt; Data analytics -&gt; Create applicaiton</p> <p></p> <p>Your application is created and you can now setup you kinesis stream as an input for your analytics application</p> <p></p> <p>Select your stream as an input and leave everything else as is</p> <p></p> <p>In the bottom of the page you will find a button to discover schema click on it and if you have enough data AWS will automatically deduct SQL schema from the MQTT messages</p> <p></p> <p>Once done AWS will show you a success message with a sample of your data once put into a tabular format</p> <p></p> <p>You can now save and continue, your data is there and the schema is ready to be acted upon we can now tackle the real analytic part of this setup</p> <p></p> <p>Click on the go to SQL editor section and start the application. AWS provides a nice set of SQL query samples over there that could let you compute most of your desired use cases. I could go over a lot of functionalities of this kinesis analytics service once there, but as I\u2019m not yet an expert into I\u2019ll leave it for another article. I have a lot of idea on how to use this tool but the most straight forward to me would be KPI computation like OEE or alerting over production line stop detecting the place where it stopped based on saturation bits</p> <p>For this demo, I will limit myself to a simple average over the last 10 seconds over a tag simulating a sinus function. I can now click save and run and will get a glimpse into the generated result</p> <p></p> <p>We are now done with setting up this 2nd part of the solution. We have data monitored through OPC that is passed in near real-time to our IoT Core which itself redirects it to a Kinesis Data Stream that gets processed by our Kinesis analytics platform.</p> <p>That makes a lot of pipes to bring our data from one end to another, however as your solution would get more complex you would find benefits in going through all of this as you can redirect your data flow from one part to another and monitor all of them using AWS tooling.</p>"},{"location":"blog/2020/07/10/bring-your-opc-ua-tags-to-the-cloud-with-aws-iot-and-kepware/#provide-real-time-dashboarding-on-top-of-your-data","title":"Provide real time dashboarding on top of your data","text":"<p>We now are about to complete the solution with a powerful and yet simple (and free)dashboarding solution called Kibana which is provided on top of elastic search.</p> <p></p> <p>This is the type of dashboard we are aiming for, the goal of this last part that would allow us to go from opc tags to actual graphics that could be shared and displayed publicly.</p> <p>But we still have a bit of configuration to complete like creating our Elasticsearch service. First go to services -&gt; Elasticsearch -&gt; Create a new domain.</p> <p></p> <p>To keep things simple I went for a development and testing deployment, this also helps to keep the cost of this experiment down.</p> <p></p> <p>Give your domain a name and pick the right instance type, here I went for a t2.small instance again to keep cost low. You can of course play with larger data set and so set up a larger instance if needed. Keep the rest as is and click next. You will have to set the rest of the parameters for access yourself, you can of course set everything to the public if you run a short time experiment but this comes with a high risk as pointed out by amazon.</p> <p>You can review your settings and confirm the Elasticsearch creation and go for a coffee as you wait for it to be up and running\u2026</p> <p></p> <p>Once up and running you can click on the Create Firehose Delivery Stream button and once again on create delivery stream. Give you stream a name and leave everything as is until destination selection.</p> <p></p> <p>Select Elasticsearch service as a destination. You then need to select your previously created elasticsearch service an give an index name and type name</p> <p></p> <p>You will have to create also an S3 backup which will be used to save the failed records so that you could recover in case of error or bug in your application. Click next and create a new IAM role if needed then complete the firehose creation. Again it might take some time to complete but stay tuned, one more step and we can finally start the dashboarding work.</p> <p>Now your elasticsearch is ready and your kinesis firehose also but no data is coming in yet, that\u2019s why we will connect the Kinesis analytics to the firehose.</p> <p></p> <p>Go back to your kinesis analytics application and click on Connect to a destination.</p> <p></p> <p>Setup the right firehose destination stream and your in-application stream which is the one created through the SQL query. Leave the rest as is and click on save and continue.</p> <p></p> <p>After some time you can go into your Kinesis firehose and the monitoring tab to see if data is flowing</p> <p></p> <p>You can also check your elasticsearch service and the index you create, you should see that some data is there and that the structure has been detected.</p> <p>We are now done with the AWS service setup and can finally grab the fruit of all our work and display those data. If you into your elasticsearch service you can find the Kibana link that we need to start setting the dashboards.</p> <p>Once in go to management -&gt; index pattern</p> <p></p> <p>Let\u2019s create our index pattern and let kibana detect our data type</p> <p></p> <p>Your result should somehow look like above, we have yet a small thing to do and it\u2019s setting a datetime field as for now we only have a Unix timestamp as a number.</p> <p></p> <p>Go to the scripted field tab and configure your scripted field as above.</p> <p> </p> <p>OK, time for some rendering. Go to visualize and create some visualization. Let\u2019s first create a simple line chart and select the opc index.</p> <p></p> <p>Configure your Y-axis as above and you X-axis as below</p> <p></p> <p>Click the run button and just enjoy your first near-real-time opc value visualization.</p> <p></p> <p>That was a long tutorial and we are only scratching the surface of what can be done here with Kibana and Kinesis Analytics. That could be a nice follow up if I find use cases internally in my company or outside who knows.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/","title":"SiLA 2 going fancy with features","text":"<p>If you have missed the introduction to SiLA 2 please have a look around here: SiLA 2 Hands-on</p> <p>This will be a more technical article but bear with me as you will gain deeper knowledge about what SiLA 2 is about. I would like to first thank UniteLabs for supporting me in writing this blog series.</p> <p>Want to skip all the talk and directly see a feature definition? go here</p> <p>Features! If you should remember one new thing in SiLA 2 I would say that\u2019s it. Features enable you :</p> <p>to describe your equipment interface precisely to automatically generate the backbone of your server to standardize equipment interface over the industry</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#what-is-a-feature","title":"What is a feature?","text":"<p>As abstract as this word may be, here we are talking about a well-defined behavior or ability of laboratory equipment. This image above shows all the components of a feature definition.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#who-can-create-it","title":"Who can create it?","text":"<p>I would say describing a feature can be down given a minimal XML knowledge which is a human-readable data format.</p> <p>Given the information that I will give you below and a simple text editor, you should be able to create your first SiLA 2 feature definition. I would still recommend having a more advanced editor like and IDE (integrated development environment) as it eases the writing of SiLA features with</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#what-makes-a-good-feature-definition","title":"What makes a good feature definition?","text":"<p>What makes a good feature definition in SiLA 2 :</p> <ul> <li>self-described: all attributes parameters are defined within a feature definition enabling a complete understanding of input and output as well a resulting equipment behavior</li> <li>self-contained: a feature contains all commands, properties needed to execute what it was defined for</li> <li>abstract: The feature definition should be as much as possible vendor independent</li> <li>human-readable: feature description contains several name and description to enable the creation of a human-readable feature</li> </ul>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#getting-started-with-your-feature","title":"Getting started with your feature","text":""},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#the-feature-definition","title":"The feature definition","text":"<p>So let\u2019s go back to my example throughout the article series on SiLA, the automated freezer.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;Feature SiLA2Version=\"0.1\" FeatureVersion=\"1.0\" Originator=\"org.silastandard\" Category=\"examples\"\n         xmlns=\"http://www.sila-standard.org\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://www.sila-standard.org https://gitlab.com/SiLA2/sila_base/raw/master/schema/FeatureDefinition.xsd\"&gt;\n    &lt;Identifier&gt;AutomatedStorage&lt;/Identifier&gt;\n    &lt;DisplayName&gt;Automated Storage&lt;/DisplayName&gt;\n    &lt;Description&gt;Feature allowing to interact with automated storage remote controls&lt;/Description&gt;\n\n         ...\n\n&lt;/Feature&gt;\n</code></pre> <p>Above you can see the first three properties to enter to define your feature :</p> <ul> <li>the feature version</li> <li>originator: who is providing this feature</li> <li>category: a tagging property to help you organize the features you create</li> </ul> <p>Then we have the three fields to be entered :</p> <ul> <li>the identifier which will be used to reference your feature on a programmatic level and is exchanged between client and server to call a feature</li> <li>the display name which gives you a human-readable text to display</li> <li>the description which provides insight on what the feature can do</li> </ul>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#the-command","title":"The command","text":"<p>Inside our \u201cAutomatedStorage\u201d feature we want to have different commands to store or retrieve rack and vials.</p> <p>Here like with the feature we need to provide an identifier, a display name, and a description.</p> <pre><code>&lt;Command&gt;\n        &lt;Identifier&gt;StoreRackWithNoContentCheck&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Store Rack without checking content&lt;/DisplayName&gt;\n        &lt;Description&gt;Store a rack without checking for its content in term of mapping of tubes position&lt;/Description&gt;\n        &lt;Observable&gt;No&lt;/Observable&gt;\n        &lt;Parameter&gt;\n            ...\n        &lt;/Parameter&gt;\n         &lt;Response&gt;\n            ...\n        &lt;/Response&gt;\n&lt;/Command&gt;\n</code></pre> <p>The additional field which is of interest here is \u201cObservable\u201d this important tag is used to define if your command is streaming data while executing like a temperature curve or a status update back to the client after starting the execution.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#the-parameters","title":"The parameters","text":"<p>The parameters are used to further describe the command and what is needed in terms of input to have the command perform the described behavior. This is where we reach the data structure definitions which are quite powerful within the FDL (Feature Definition Language) of SiLA.</p> <p>But first, let see how to input a simple parameter like a string or decimal value.</p> <p><pre><code>&lt;Command&gt;\n    ...\n    &lt;Parameter&gt;\n        &lt;Identifier&gt;RackBarcode&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Rack Barcode&lt;/DisplayName&gt;\n        &lt;Description&gt;The barcode of the rack that will be inserted into the automated freezer&lt;/Description&gt;\n        &lt;DataType&gt;\n            &lt;Basic&gt;String&lt;/Basic&gt;\n        &lt;/DataType&gt;\n    &lt;/Parameter&gt;\n    &lt;Parameter&gt;\n        &lt;Identifier&gt;RackHeight&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Rack Height&lt;/DisplayName&gt;\n        &lt;Description&gt;The height of the rack that will be inserted&lt;/Description&gt;\n        &lt;DataType&gt;\n            &lt;Basic&gt;Real&lt;/Basic&gt;\n        &lt;/DataType&gt;\n    &lt;/Parameter&gt;\n  &lt;/Command&gt;\n</code></pre> As we have seen for the feature and command there is some basic field required. The additional one I want to drive your attention to is the DataType tag, this is where we define the type of data that will be passed to the command and in some cases a complex structure.</p> <p>Here we are making use of the basic data types that are available in SiLA, if you use an IDE has advised above you should have auto-completion for it otherwise here is the list of available types: Real, Boolean, Date, Integer, SmallBinary, String, Time, Timestamp.</p> <p>You can already do a lot with those, for most simple devices like readers or scales and sensors, this would be sufficient. However, in our automated freezer use case, we might want to pass a list of expected vials that should be in a rack, and for this, we need the other data types that are available.</p> <pre><code>&lt;Command&gt;\n    ...\n    &lt;Parameter&gt;\n        &lt;Identifier&gt;ExpectedRackContent&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Expected Rack Content&lt;/DisplayName&gt;\n        &lt;Description&gt;The vials barcode and position which are expected within the rack&lt;/Description&gt;\n        &lt;DataType&gt;\n            &lt;List&gt;\n                &lt;DataType&gt;\n                    &lt;Structure&gt;\n                        &lt;Element&gt;\n                            &lt;Identifier&gt;RackPosition&lt;/Identifier&gt;\n                            &lt;DisplayName&gt;Rack Position&lt;/DisplayName&gt;\n                            &lt;Description&gt;A cell within a rack&lt;/Description&gt;\n                            &lt;DataType&gt;\n                                &lt;Basic&gt;String&lt;/Basic&gt;\n                            &lt;/DataType&gt;\n                        &lt;/Element&gt;\n                        &lt;Element&gt;\n                            &lt;Identifier&gt;VialBarcode&lt;/Identifier&gt;\n                            &lt;DisplayName&gt;Vial Barcode&lt;/DisplayName&gt;\n                            &lt;Description&gt;the barcode of the vial within the rack position given&lt;/Description&gt;\n                            &lt;DataType&gt;\n                                &lt;Basic&gt;String&lt;/Basic&gt;\n                            &lt;/DataType&gt;\n                        &lt;/Element&gt;\n                        &lt;Element&gt;\n                            &lt;Identifier&gt;VialVolume&lt;/Identifier&gt;\n                            &lt;DisplayName&gt;Vial Volume&lt;/DisplayName&gt;\n                            &lt;Description&gt;The volume of material within the Vial in ml&lt;/Description&gt;\n                            &lt;DataType&gt;\n                                &lt;Basic&gt;String&lt;/Basic&gt;\n                            &lt;/DataType&gt;\n                        &lt;/Element&gt;\n                    &lt;/Structure&gt;\n                &lt;/DataType&gt;\n            &lt;/List&gt;\n        &lt;/DataType&gt;\n    &lt;/Parameter&gt;\n&lt;/Command&gt;\n</code></pre> <p>In the example above you can see what a more advanced use case of the parameter might look like. For developers, these structures would seem familiar as the List and Structure elements are quite similar to lists and classes in programming languages and that\u2019s what SiLA would translate those structures too.</p> <p>What is important to get out of this example is that you won\u2019t be limited by the SiLA command parameter definition and you can structure them as you want to model the data that you need to input into your command.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#the-responses","title":"The responses","text":"<p>In SiLA the responses do work similarly to the parameters and there can be multiple response structures possible from one command. I won\u2019t detail how to create those as they are quite similar to parameters and you can reuse the knowledge above to create them.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#the-properties","title":"The properties","text":"<p>Outside of the commands which are your interactive entry point to communicate with the SiLA server you might find it interesting to define properties to your feature. In our example, the temperature of the automated Freezer would be a nice value to be able to monitor.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#building-reusable-types","title":"Building reusable types","text":"<p>To be able to have a cleaner feature you can use data type definition, those allow you to have a predefined data structure which will be shared across your features and commands thus allowing you to reuse some of your underlying components and have a more object-oriented approach to SiLA2</p> <pre><code>&lt;DataTypeDefinition&gt;\n      &lt;Identifier&gt;Rack&lt;/Identifier&gt;\n      &lt;DisplayName&gt;Rack&lt;/DisplayName&gt;\n      &lt;Description&gt;Rack entity containing containers &lt;/Description&gt;\n      &lt;DataType&gt;\n          ...\n      &lt;/DataType&gt;\n&lt;/DataTypeDefinition&gt;\n</code></pre> <p>Once you have created this DataTypeDefinition in your feature you can simply call it in a command like below</p> <pre><code>&lt;Command&gt;\n    ...\n    &lt;Parameter&gt;\n        ...\n        &lt;DataType&gt;\n            &lt;DataTypeIdentifier&gt;Rack&lt;/DataTypeIdentifier&gt;\n        &lt;/DataType&gt;\n    &lt;/Parameter&gt;\n    ...\n&lt;/Command&gt;\n</code></pre>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#experimenting-with-it","title":"Experimenting with it","text":"<p>Once again I can spin up my favorite SiLA Browser provided by UniteLabs and start also my server</p> <p></p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#wrapping-up","title":"Wrapping up","text":"<p>Look at the final feature definition to remember the important feature element we have discovered today</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;Feature SiLA2Version=\"0.1\" FeatureVersion=\"1.0\" Originator=\"org.silastandard\" Category=\"examples\"\n         xmlns=\"http://www.sila-standard.org\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://www.sila-standard.org https://gitlab.com/SiLA2/sila_base/raw/master/schema/FeatureDefinition.xsd\"&gt;\n    &lt;Identifier&gt;AutomatedStorage&lt;/Identifier&gt;\n    &lt;DisplayName&gt;Automated Storage&lt;/DisplayName&gt;\n    &lt;Description&gt;Feature allowing to interact with automated storage remote controls&lt;/Description&gt;\n\n    &lt;DataTypeDefinition&gt;\n        &lt;Identifier&gt;RackContent&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Rack Content&lt;/DisplayName&gt;\n        &lt;Description&gt;Rack entity containing containers with their location&lt;/Description&gt;\n        &lt;DataType&gt;\n            &lt;Structure&gt;\n                &lt;Element&gt;\n                    &lt;Identifier&gt;RackPosition&lt;/Identifier&gt;\n                    &lt;DisplayName&gt;Rack Position&lt;/DisplayName&gt;\n                    &lt;Description&gt;A cell within a rack&lt;/Description&gt;\n                    &lt;DataType&gt;\n                        &lt;Basic&gt;String&lt;/Basic&gt;\n                    &lt;/DataType&gt;\n                &lt;/Element&gt;\n                &lt;Element&gt;\n                    &lt;Identifier&gt;VialBarcode&lt;/Identifier&gt;\n                    &lt;DisplayName&gt;Vial Barcode&lt;/DisplayName&gt;\n                    &lt;Description&gt;the barcode of the vial within the rack position given&lt;/Description&gt;\n                    &lt;DataType&gt;\n                        &lt;Basic&gt;String&lt;/Basic&gt;\n                    &lt;/DataType&gt;\n                &lt;/Element&gt;\n                &lt;Element&gt;\n                    &lt;Identifier&gt;VialVolume&lt;/Identifier&gt;\n                    &lt;DisplayName&gt;Vial Volume&lt;/DisplayName&gt;\n                    &lt;Description&gt;The volume of material within the Vial in ml&lt;/Description&gt;\n                    &lt;DataType&gt;\n                        &lt;Basic&gt;String&lt;/Basic&gt;\n                    &lt;/DataType&gt;\n                &lt;/Element&gt;\n            &lt;/Structure&gt;\n        &lt;/DataType&gt;\n    &lt;/DataTypeDefinition&gt;\n\n    &lt;Command&gt;\n        &lt;Identifier&gt;StoreRackWithNoContentCheck&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Store Rack without checking content&lt;/DisplayName&gt;\n        &lt;Description&gt;Store a rack without checking for its content in term of mapping of tubes position&lt;/Description&gt;\n        &lt;Observable&gt;No&lt;/Observable&gt;\n        &lt;Parameter&gt;\n            &lt;Identifier&gt;RackBarcode&lt;/Identifier&gt;\n            &lt;DisplayName&gt;Rack Barcode&lt;/DisplayName&gt;\n            &lt;Description&gt;The barcode of the rack that will be inserted into the automated freezer&lt;/Description&gt;\n            &lt;DataType&gt;\n                &lt;Basic&gt;String&lt;/Basic&gt;\n            &lt;/DataType&gt;\n        &lt;/Parameter&gt;\n        &lt;Parameter&gt;\n            &lt;Identifier&gt;ExpectedRackContent&lt;/Identifier&gt;\n            &lt;DisplayName&gt;Expected Rack Content&lt;/DisplayName&gt;\n            &lt;Description&gt;The vials barcode and position which are expected within the rack&lt;/Description&gt;\n            &lt;DataType&gt;\n                &lt;DataTypeIdentifier&gt;RackContent&lt;/DataTypeIdentifier&gt;\n            &lt;/DataType&gt;\n        &lt;/Parameter&gt;\n        &lt;Response&gt;\n            &lt;Identifier&gt;ActualRackContent&lt;/Identifier&gt;\n            &lt;DisplayName&gt;Actual Rack Content&lt;/DisplayName&gt;\n            &lt;Description&gt;Content of the rack with location and barcode of vials inside&lt;/Description&gt;\n            &lt;DataType&gt;\n                &lt;DataTypeIdentifier&gt;RackContent&lt;/DataTypeIdentifier&gt;\n            &lt;/DataType&gt;\n        &lt;/Response&gt;\n    &lt;/Command&gt;\n\n\n\n    &lt;Property&gt;\n        &lt;Identifier&gt;FreezerTemperature&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Freezer Temperature&lt;/DisplayName&gt;\n        &lt;Description&gt;The current temperature of the freezer&lt;/Description&gt;\n        &lt;DataType&gt;\n            &lt;Basic&gt;Real&lt;/Basic&gt;\n        &lt;/DataType&gt;\n        &lt;Observable&gt;Yes&lt;/Observable&gt;\n    &lt;/Property&gt;\n\n&lt;/Feature&gt;\n</code></pre> <p>You should now have a better understanding of this feature definition language SiLA is using, it should cover many use cases we might think of. I have a small exception in mind for binary data which needs to be loaded as such because of the volume or architecture of the underlying instruments.</p> <p>There is more to explore in the SiLA repository mentioned as a link below, for example, the SmallBinary data type could fill some of the use cases mentioned just before.</p> <p>I now need to get further into the server implementation and will probably pick up an existing automated freezer like a Liconic or Arktic storage which I\u2019m working on and will provide a wrapper for those so that it can be tested in the labs.</p>"},{"location":"blog/2020/07/10/sila-2-going-fancy-with-features/#useful-links","title":"Useful Links","text":"<p>Sila2 Website</p> <p>Sila2 Repository</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/","title":"SiLA 2 hands on : bringing automation to the laboratory","text":"<p>Ever heard about SiLA ? It stands for Standard in Lab Automation, and if you\u2019re not working in automation of life science laboratories, you are probably hearing about this for the first time. In this blog post I will introduce you the benefits of SiLA 2 (the latest version of the standard) and show a hands-on example how the standard can help and simplify laboratory equipment integration into your IT systems.</p> <p></p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#lets-set-the-scene","title":"Let\u2019s set the scene","text":"<p>In a perfect world all your equipment would provide the same way of controlling the functions and accessing the data. Integrating the equipment into your IT landscape would become both consistent and less tedious.</p> <p>Sadly, until now, several issues may occur :</p> <ul> <li>Your equipment was not designed to be integrated into any IT system and you are left with no choice than to live with it or purchase new equipment</li> <li>Your equipment has some kind of interface but very few of its capacities are exposed to interact with. You may not even be able to extract the data it produces</li> <li>In the best case, you have a set of integration points covering most of the device functionalities, well documented and written in modern, non-proprietary language</li> <li>Unfortunately, even if you reach the best case scenario you would still have to write a custom piece of software for each and every equipment you have. It would result in a huge library of disparate implementations for various equipment with no common ground.</li> </ul>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#solving-the-integration-issues-with-sila-2","title":"Solving the integration issues with SiLA 2","text":"<p>SiLA 2 is a communication standard for laboratory instruments, such as readers, liquid handling robots and chromatography and other analytical equipment. However, with the new 2nd version of SiLA, it can also be used as a communication protocol between any microservices, even completely virtual. This makes it possible to track, monitor and even remote control assets, which makes it also capable in manufacturing use cases.</p> <p>Additionally, the SiLA 2 standard is self descriptive, which means that by connecting to the interface, you or any software could learn exactly what the device can do and how to use it. This makes it possible to create software tools that can readily operate any SiLA 2 supported instrument without drivers or configurations.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#client-server-concept","title":"Client - Server concept","text":"<p>It is based on a client \u2014 server communication model where the server exposes it\u2019s capabilities to all clients in a consistent way. The interactions with the server (e.g. an incubator) are grouped into SiLA Features. Each Feature (e.g. shaking or temperature control) encompasses commands and data outlets related to the same instrument capability.</p> <p></p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#feature-definitions","title":"Feature definitions","text":"<p>Servers can implement a set of features that the client can use selectively based on the use case. The client could be a LIMS system, requesting system or an inventory management system. Even another lab instrument could be a client to communicate to the next device in the lab workflow, thus enabling device to device communication, robotic integration and closed-loop feedback. One example would be a scale asking a barcode reader the ID of the current sample and humidity from a sensor to associate with the weight measurement.</p> <p></p> <p>The features of a device (that is, a SiLA server) are described using an XML file where the functionality is described using:</p> <p>Properties: data values that can be static (e.g. serial number) or dynamic (e.g. current temperature) Commands: an interaction to control or pass information to/from the SiLA Server Parameters: expected information required to execute the command Return values: expected output of the command Errors: expected errors that might occur during the operation For example you could have an automated freezer with a tube storage feature with a \u201cGet tube\u201dcommand that takes a parameter \u201cTube IDs\u201d as list a of strings and as returns the \u201cDestination\u201d as a position of the tubes on the output rack.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#automated-server-and-feature-discovery","title":"Automated server and feature discovery","text":"<p>The SiLA protocol also comes with a zero configuration discovery service which allows a client to broadcast a message to discover all available servers and their associated features. This is the perfect match if you are in a very dynamic environment where instruments are often relocated from one system or laboratory to another.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#and-many-more","title":"And many more\u2026","text":"<p>The SiLA standard defines many more capabilities but it also standardized features so that all providers could stick to the same common commands and interactions. Examples of further capabilities provided by SiLA 2:</p> <p>Data types and transport Encryption and authentication Property subscription Command progress updates Instrument locking etc. There\u2019s a lot to explore with SiLA 2 and I have included links in the end of the article for you to read more. Now that we are familiar with the basic SiLA 2 concepts, let\u2019s get our hands on the SiLA protocol. We are going to implement the automated storage as an example to see how it works in practice.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#building-a-simple-storage-system-sila-2-driver","title":"Building a simple storage system SiLA 2 driver","text":"<p>There are many tools and examples available in the SiLA 2 repository that help new developers get started. For instance, I\u2019ll start developing the automated storage server from the hello_sila example project and modify it to fit my needs. The full code for this example is available here : https://github.com/mcroissant/sila_simple_storage</p> <p>The follow up section may be technical and Java focused but you can find many resources for other languages directly on the SiLA 2 repositories : https://gitlab.com/SiLA2</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#creating-a-feature","title":"Creating a feature","text":"<p>The first step in developing a SiLA 2 server is to create the feature definition which all server-client interactions will be based.</p> <p>Our feature contains a simple command with no response and a simple parameter. The interactions could of course get more sophisticated using structures and more complex return values, but that will be a story for the next article.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;Feature SiLA2Version=\"0.1\" FeatureVersion=\"1.0\" Originator=\"org.silastandard\" Category=\"examples\"\n         xmlns=\"http://www.sila-standard.org\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://www.sila-standard.org https://gitlab.com/SiLA2/sila_base/raw/master/schema/FeatureDefinition.xsd\"&gt;\n    &lt;Identifier&gt;AutomatedStorage&lt;/Identifier&gt;\n    &lt;DisplayName&gt;Automated Storage&lt;/DisplayName&gt;\n    &lt;Description&gt;Feature allowing to interact with automated storage remote controls&lt;/Description&gt;\n    &lt;Command&gt;\n        &lt;Identifier&gt;StoreRackWithNoContentCheck&lt;/Identifier&gt;\n        &lt;DisplayName&gt;Store Rack without checking content&lt;/DisplayName&gt;\n        &lt;Description&gt;Store a rack without checking for its content in term of mapping of tubes position&lt;/Description&gt;\n        &lt;Observable&gt;No&lt;/Observable&gt;\n        &lt;Parameter&gt;\n            &lt;Identifier&gt;RackBarcode&lt;/Identifier&gt;\n            &lt;DisplayName&gt;Rack Barcode&lt;/DisplayName&gt;\n            &lt;Description&gt;The barcode of the rack that will be inserted into the automated freezer&lt;/Description&gt;\n            &lt;DataType&gt;\n                &lt;Basic&gt;String&lt;/Basic&gt;\n            &lt;/DataType&gt;\n        &lt;/Parameter&gt;\n    &lt;/Command&gt;\n&lt;/Feature&gt;\n</code></pre> <p>As you can see feature definition are self explanatory files written in a comprehensive XML format. The feature file will be validated and further used to generate the exchanged messages between server and client.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#adding-the-feature-to-the-server","title":"Adding the feature to the server","text":"<p>Adding a feature to a server is relatively easy and is a one line as you can see just below. From now on our server would expose this as one of its features and advertise it to clients asking what the server is capable of.</p> <pre><code>  builder.addFeature(\n      \"org.silastandard/examples/v1/AutomatedStorage\",\n      getResourceContent(\"AutomatedStorage.sila.xml\"),\n      new AutomatedStorageImpl()\n);\n</code></pre>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#implementing-the-feature","title":"Implementing the feature","text":"<p>As the base of the feature as already been generated automatically by the SiLA protocol what\u2019s left for us to do is to extend the functionality of this base implementation. If you want to know more about the automated code generation please leave a comment on this could be an interesting starting point for the following article.</p> <p>The example below shows what the minimum implementation could look like with input parameter validation and error responses as well as response construction.</p> <pre><code>package sila_java.servers.automated_freezer.automated_storage;\n\nimport sila2.org.silastandard.examples.automatedstorage.v1.AutomatedStorageGrpc;\nimport sila2.org.silastandard.examples.automatedstorage.v1.AutomatedStorageOuterClass;\nimport sila_java.library.core.sila.types.SiLAErrors;\n\npublic class AutomatedStorageImpl extends AutomatedStorageGrpc.AutomatedStorageImplBase{\n\n    /**\n     */\n    @Override\n    public void storeRackWithNoContentCheck(sila2.org.silastandard.examples.automatedstorage.v1.AutomatedStorageOuterClass.StoreRackWithNoContentCheck_Parameters request,\n                                            io.grpc.stub.StreamObserver&lt;sila2.org.silastandard.examples.automatedstorage.v1.AutomatedStorageOuterClass.StoreRackWithNoContentCheck_Responses&gt; responseObserver) {\n\n\n        /*\n        Different parameters can be checked, it is mandatory to throw Validation Errors in case of\n        missing parameters, which will be done automatically in the future.\n        */\n        if (!request.hasRackBarcode()) {\n            responseObserver.onError(SiLAErrors.generateValidationError(\n                    \"Rack Barcode\",\n                    \"Rack barcode parameter was not set\",\n                    \"Specify a barcode with at least one character\"));\n            return;\n        }\n\n        /**\n         * TODO implement any behaviour needed on the server side for the equipment\n         */\n\n        AutomatedStorageOuterClass.StoreRackWithNoContentCheck_Responses result =\n                AutomatedStorageOuterClass.StoreRackWithNoContentCheck_Responses\n                        .newBuilder()\n                        .build();\n\n        responseObserver.onNext(result);\n        responseObserver.onCompleted();\n\n    }\n}\n</code></pre>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#launching-our-server","title":"Launching our server","text":"<p>Once our server is compiled and launched we can use a free tool provided by UniteLabs allowing our browser to act as a SiLA client you can download it freely here : link</p> <p>Automatically created interface of our server feature within SiLA Browser From there we could directly control our automated storage and tell it to store a given rack. This interface is quite useful for development and debugging but as stated before you would probably integrate your freezer directly with an other system like your inventory or your LIMS.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#wrapping-up","title":"Wrapping up","text":"<p>We have just scratched the surface of the SiLA 2 protocol and it is very promising as the manufacturer adoption is rising we will be able to leverage the benefits of it and integrate new equipment faster and in a more consistent way.</p> <p>I am writing another article on the subject and will provide a full fledged implementation of the automated storage case so that it can serve as a demo. Let me know if you are interested.</p>"},{"location":"blog/2019/10/29/sila-2-hands-on--bringing-automation-to-the-laboratory/#want-to-know-more-on-sila","title":"Want to know more on SiLA ?","text":""},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/","title":"Manipulating YAML and OpenApi specifications with yq","text":"<p>Yq is a powerful command-line tool designed to make working with YAML, JSON, and XML files easier and more efficient. it is build to feell a lot like jq an other popular cli.</p> <p>YQ functionalities support YAML, making it an invaluable resource for us developers, DevOps engineers, and data enthusiasts who frequently interact with configuration files or structured data formats. </p> <p>With YQ, you can query, manipulate, and transform data in a concise and expressive way, all while maintaining readability. Whether you're automating workflows, debugging configuration issues, or managing complex infrastructure setups, YQ streamlines these tasks, saving you both time and effort. </p>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#general-usage-of-yq-with-openapi","title":"General usage of yq with openapi","text":"<p>You can use yq in many ways as YAML gained quite a lot of popularity over json in the last years, obviously the whole container and Kubernetes cluster operation aspects come to mind, but I would like to take a slightly different turn on this and show you a few of the wonders you can do on OpenApi  specification with this tool.</p>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#list-paths","title":"list paths","text":"<pre><code>yq eval '.paths | keys[]' petstore.yml\n</code></pre> <p>Output</p> <pre><code>/pets\n/pets/{petId}\n</code></pre>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#list-the-servers","title":"list the servers","text":"<pre><code>yq eval '.servers[].url' petstore.yml\n</code></pre> <p>Output <pre><code>http://petstore.swagger.io/v1\n</code></pre></p>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#more-advanced-pattern","title":"More advanced pattern","text":""},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#search","title":"Search","text":"<pre><code>yq eval  '.paths[] | select(has(\"security\")) | keys[]' petstore.yml\n</code></pre> <p>This will return you the secured endpoint list, obviously in this example there are none</p>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#merge-two-yamls-to-add-a-security-scheme","title":"Merge two yamls to add a security scheme","text":"<p>You could leverage this call to apply a security scheme to multiple APIs as part of your CICD, this can come very handy whenever you have additional layers on topc of your API like a Gateway.</p> security_scheme.yml<pre><code>openapi: 3.0.1\ncomponents:\n  securitySchemes:\n    ApiAuth:\n      type: apiKey\n      in: header\n      name: X-API-KEY\n</code></pre> <pre><code>yq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' petstore.yml security_scheme.yml\n</code></pre>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#applying-a-security-scheme-to-paths-in-your-api","title":"Applying a security scheme to paths in your API","text":"<pre><code>yq eval  '.paths[]+= {\"security\": [{\"ApiAuth\":[]}]}' petstore.yml\n</code></pre> <p>This one will actually add an \"ApiAuth\" security scheme as well as the security element to your different paths.</p>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#replace-auth-in-openapi-yml","title":"Replace auth in openapi yml","text":"<p>As a final call I leave with this one yq query that took me a bit longer to figure out but that is now part of some of the CI pipeline I use where you can replace an existing security scheme by an other one.</p> <pre><code> yq eval '.paths[] |=    (.. | select(has(\"security\")) | .security[]| .basicAuth |key) = \"apiAuth\" ' availability.yml\n</code></pre>"},{"location":"blog/2024/12/18/manipulating-yaml-and-openapi-specifications-with-yq/#conclusion","title":"Conclusion","text":"<p>Working with OpenApi specificationisn\u2019t just about designing APIs. There are plenty of occasion where you would like to manipulate the specification. Yq stands out as a reliable, efficient, and flexible tool for these tasks. By incorporating yq into your toolkit, you can simplify your workflows and enhance productivity. </p>"},{"location":"courses/apis/Introduction/01_what_api/","title":"What's an API","text":""},{"location":"courses/apis/Introduction/01_what_api/#1-introduction-why-apis-matter","title":"1. Introduction: Why APIs Matter","text":"<p>APIs (Application Programming Interfaces) are the backbone of modern software development and integration. They allow different applications to communicate and work together seamlessly, those are also key for different components of a single system to communicate and evolve in a more independent manner in that instance they work as interfaces (as understood in coding).</p>"},{"location":"courses/apis/Introduction/01_what_api/#example","title":"Example","text":"<p>Think about how your favorite food delivery smartphone application shows restaurant menus, lets you place orders, and tracks delivery status. Behind the scenes, APIs connect the smartphone app to the delivery provider servers, payment gateways, and mapping services.</p>"},{"location":"courses/apis/Introduction/01_what_api/#2-core-concept-what-is-an-api","title":"2. Core Concept: What Is an API?","text":"<p>Definition: An API (Application Programming Interfaces) is a contract defining how a service is provided to consuming applications (any piece of software with a distinct function). The contract usually stipulates which requests and responses are available and their corresponding structures</p>"},{"location":"courses/apis/Introduction/01_what_api/#what-happens-in-the-physical-world","title":"What happens in the physical world","text":"<p>Imagine you are at a restaurant (preferably French or Italian ;-) ), they way you interact within this context is rather bounded and the request and results are defined in advance and you could map this to what is foud in APIs in the following way : - Menu: Represents the API contract, showing what you can request. - Kitchen: Handles the actual work (hidden from you). - Order: Your request to the API. - Meal: The response delivered back to you.</p>"},{"location":"courses/apis/Introduction/01_what_api/#3-components-of-an-api","title":"3. Components of an API","text":"<p>Now that you have some idea of what an API is, let's dive deeper into its constituents. All three of them have of course many variation possible depending on the API purpose and implementation.</p>"},{"location":"courses/apis/Introduction/01_what_api/#endpoints","title":"Endpoints","text":"<p>The URL or address where an API can be accessed.</p>"},{"location":"courses/apis/Introduction/01_what_api/#requests-and-responses","title":"Requests and Responses","text":"<ul> <li>Request: What you send to the API, specifying what you need.</li> <li>Response: The data the API sends back to you.</li> </ul>"},{"location":"courses/apis/Introduction/01_what_api/#data-formats","title":"Data Formats","text":"<p>Web APIs often use:</p> <ul> <li>JSON (JavaScript Object Notation): <code>{ \"key\": \"value\" }</code></li> <li>XML: <code>&lt;key&gt;value&lt;/key&gt;</code></li> </ul> <p>however there is no limit in what format is used by APIs</p>"},{"location":"courses/apis/Introduction/01_what_api/#4-types-of-apis","title":"4. Types of APIs","text":"<p>Most type of programatic interface can be seen as APIs, here are a few types you wan't to consider.</p>"},{"location":"courses/apis/Introduction/01_what_api/#web-apis","title":"Web APIs","text":"<p>Web APIs are one of the most commonly know type of APIs as they are predominently used on the internet, again we are still on a high level definition as many different implementation are available in this context like :  - REST (Representational State Transfer): Most common, uses HTTP. - GraphQL: Flexible query-based API, usually leveraged by frontend components.</p>"},{"location":"courses/apis/Introduction/01_what_api/#library-apis","title":"Library APIs","text":"<p>Used within programming, libraries and frameworks for developers are prebuilt functions that can be leveraged and avoids you to build your own.</p>"},{"location":"courses/apis/Introduction/01_what_api/#remote-method-invocation-or-protocol-call","title":"Remote Method Invocation or Protocol Call","text":"<p>RMI or RPC allow multiple components of a distributed system to exchange together over the network, those are usually reserved for components developed as part of the same system and rarely exposed to the public.</p>"},{"location":"courses/apis/Introduction/01_what_api/#os-apis","title":"OS APIs","text":"<p>Enable interaction with operating systems, e.g., file systems or hardware.</p>"},{"location":"courses/apis/Introduction/01_what_api/#5-real-world-examples","title":"5. Real-World Examples","text":""},{"location":"courses/apis/Introduction/01_what_api/#example-1-weather-data","title":"Example 1: Weather Data","text":"<p>A first API that could want to leverage is OpenWeatherMap, after subscription (free) you can get an API key which secures you call to their server and get weather information for your local area with just one call</p> <p>Try-it</p> <p>You could give it a go using python</p> <pre><code>import requests\n\nurl = \"https://api.openweathermap.org/data/3.0/weather?q=Strasbourg&amp;appid=YOUR_API_KEY\"\nresponse = requests.get(url)\nprint(response.json())\n</code></pre> <p>or type the url directly in your browser, as it is a rest API it leverages the same protocol your browser does to navigate the web</p>"},{"location":"courses/apis/Introduction/01_what_api/#example-2-python-file-api","title":"Example 2: Python File API","text":"<p>Here is an other example show casing the python File API</p> <p>Try-it</p> <pre><code># File interaction with Python File API\n\n# Step 1: Create and write to a file\nprint(\"Creating and writing to a file...\")\nwith open(\"example.txt\", \"w\") as file:\n    file.write(\"Hello, this is a file API example.\\n\")\n    file.write(\"We are writing this text to the file.\\n\")\nprint(\"File created and initial content written.\\n\")\n\n# Step 2: Append additional data to the file\nprint(\"Appending new data to the file...\")\nwith open(\"example.txt\", \"a\") as file:\n    file.write(\"Adding a new line to the file.\\n\")\nprint(\"New data appended.\\n\")\n\n# Step 3: Verify the appended content\nprint(\"Re-reading the file to verify appended content:\")\nwith open(\"example.txt\", \"r\") as file:\n    updated_content = file.read()\n    print(updated_content)\n</code></pre>"},{"location":"courses/apis/Introduction/01_what_api/#7-hands-on-activity","title":"7. Hands-On Activity","text":"<ol> <li>Choose a public API from https://github.com/public-apis/public-apis preferably without any authentication or free of use.</li> <li>Use a tool like Bruno CLI or curl to send a request.</li> <li>Retrieve specific data.</li> </ol> <p>--</p>"},{"location":"courses/apis/Introduction/01_what_api/#8-conclusion","title":"8. Conclusion","text":""},{"location":"courses/apis/Introduction/01_what_api/#common-misconceptions","title":"Common Misconceptions","text":"<ul> <li>APIs are not limited to web services\u2014they can exist in libraries, etc.</li> <li>APIs themselves don\u2019t store data\u2014they provide access to it.</li> </ul>"},{"location":"courses/apis/Introduction/01_what_api/#importance-of-apis-in-software-ecosystems","title":"Importance of APIs in Software Ecosystems","text":"<ul> <li>Integration: APIs enable services to work together (e.g., payment gateways, maps, social logins, OS and software).</li> <li>Marketplaces: APIs drive businesses like Stripe, Twilio, and Google Maps, you can make money out of an API.</li> </ul>"},{"location":"courses/apis/Introduction/01_what_api/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>APIs define how software applications interact.</li> <li>They use endpoints, requests, and responses to exchange data.</li> <li>APIs simplify complex integrations in the modern digital ecosystem.</li> </ul>"},{"location":"courses/apis/Introduction/02_client_server/","title":"Client-server paradigm","text":""},{"location":"courses/apis/Introduction/02_client_server/#what-is-a-client-server-interaction","title":"What is a client server interaction","text":"<pre><code>sequenceDiagram\n  autonumber\n  Client-&gt;&gt;Server: Hello Server, how are you?\n  loop Compute\n      Server-&gt;&gt;Server: How am I doing\n  end\n  Server--&gt;&gt;Client: Great!</code></pre> <p>This basic interaction is based on requests and responses being exchanged between the client and the server. The client is usually the one initiating the interaction with the server knowing in advance how to contact it.</p> <p>The interaction between the client and the server is most of the time supported by an underlying network layer even if this is not a pre-requisites as this concept could be used inside of a single system.</p>"},{"location":"courses/apis/Introduction/02_client_server/#client","title":"Client","text":"<p>Clients are devices or applications that request services or resources from a server. The most common client that everyone know being web browsers, mobile apps or just any kind of software in general.</p> <p>What distinguisheds the client from the server is the fact that it is the one to initiate the transaction and process the response. </p> <p>In more complex use cases like Internet of Things (IoT) clients can also be servers which enables device to device communications. You could think of a communication between cars on the road to exchange traffic condition as an example of this.</p>"},{"location":"courses/apis/Introduction/02_client_server/#server","title":"Server","text":"<p>A server is a system or application that provides  resources, data, or services to clients. Here you should not understand it in the sense of the physical server even though this is where the name is derived from.</p> <p>The server is a software piece offering something of value to the client upon request. Servers can handle multiple client requests simultaneously and require more computing power than the client application.</p>"},{"location":"courses/apis/Introduction/02_client_server/#client-server-communication-protocols","title":"Client server communication protocols","text":"<p>Client server exchanges can be very diverse in their use cases. To support such diversity the industry has come up with a variety of different protocols with their specificities.</p> <p>Here is a short list of them : </p> <ul> <li> <p>HTTP (HyperText Transfer Protocol) : used by web pages and services, rest apis</p> </li> <li> <p>FTP (File Transfer Protocol) : used for file transfers to and from servers</p> </li> <li> <p>SMTP (Simple Mail Transfer Protocol) : specific to email servers and clients</p> </li> <li> <p>TCP/IP (Transmission Control Protocol / Internet Protocol) : lower level of protocol reused by others like HTTP and FTP</p> </li> <li> <p>UDP (User Datagram Protocol) : leveraged by streaming services and online gaming, mostly real time use cases</p> </li> <li> <p>and many more..</p> </li> </ul>"},{"location":"courses/apis/Introduction/02_client_server/#example-web-browsing","title":"Example : Web browsing","text":"<pre><code>sequenceDiagram\n  autonumber\n  Browser -&gt;&gt; Server: GET /index.html\n  Server--&gt;&gt;Browser: index.html\n  Browser -&gt;&gt; Server: GET /pictures/profile/user876857.png\n  Server--&gt;&gt;Browser: /pictures/profile/user876857.png\n  Browser -&gt;&gt; Server: GET /script.js\n  Server--&gt;&gt;Browser: /script.js</code></pre> <p>The above sequence shows a simplified view on what is hapenning in your browser whenever you open a website : </p> <ol> <li>Your browser asks for a given webpage to the server</li> <li> <p>The Server returns the web page to you</p> <p>Html web pages are often containing references to other resources that need to be loaded for the page to be displayed, this can be images, scripts that will be executed in your browser and other type of resources.</p> </li> <li> <p>You browser is now requesting other resources that are required by the page like the user picture</p> </li> <li> <p>Server return the picture</p> </li> <li> <p>You browser requests a javascript file most likely containing some dynamic behavior the page will have</p> </li> <li> <p>The server returns the required script</p> </li> </ol> <p>These interactions will continue on and on until enough resources have been exchanged for the page to start loading, those are called synchronuous loading as the web page is not starting to be rendered until those resources are returned. This can lead to long loading time and that's why most modern web pages implement some asynchronuous loading behaviors to reduce the time necessary for the page to start to display. </p> <p>Try-it</p> <p>Try opening the developer tools in your browser.</p> <p>You'll be able to check the behavior of every site you are opening and see how the different resources that are in your web page are being loaded.</p> <p>Ctrl+Shift+I in Chrome  Chrome Developer tools network tab </p>"},{"location":"courses/apis/Introduction/03_network_basics/","title":"Network basics","text":""},{"location":"courses/apis/Introduction/05_http/","title":"HTTP Protocol","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/category/api/","title":"api","text":""},{"location":"blog/category/cicd/","title":"cicd","text":""},{"location":"blog/category/yaml/","title":"yaml","text":""},{"location":"blog/category/openapi/","title":"openapi","text":""},{"location":"blog/category/ci/","title":"ci","text":""},{"location":"blog/category/iot/","title":"iot","text":""},{"location":"blog/category/cloud/","title":"cloud","text":""},{"location":"blog/category/laboratory/","title":"laboratory","text":""},{"location":"blog/category/automation/","title":"automation","text":""}]}